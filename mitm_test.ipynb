{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hey there!\n",
        "Let's continue - now that we have the .flow file, we can parse and analyse it."
      ],
      "metadata": {
        "id": "mzsz3hLhCZv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this if you don't have the modules installed\n",
        "!pip install mitmproxy pandas requests datetime json"
      ],
      "metadata": {
        "id": "3LBqe9nwWuGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from mitmproxy import io\n",
        "from mitmproxy.exceptions import FlowReadException\n",
        "from mitmproxy.io import FlowReader\n",
        "import sys\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import requests"
      ],
      "metadata": {
        "id": "g8W6lB-NXKi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put the filename that you chose before (e.g. appname.flow) here\n"
      ],
      "metadata": {
        "id": "NsM8ZddBCtDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = \"makemore.flow\"\n",
        "output = file.split(sep=\".\")[0] + \".csv\""
      ],
      "metadata": {
        "id": "SvW_pUZCw2Gc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we read the .flow file and turn it into a csv fo further analysis"
      ],
      "metadata": {
        "id": "8t87DvWcDAnY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mB0YToKJWLX-"
      },
      "outputs": [],
      "source": [
        "def clean_bytes(data):\n",
        "    if not data:\n",
        "        return \"\"\n",
        "    try:\n",
        "        return data.decode(\"utf-8\", errors=\"replace\")\n",
        "    except:\n",
        "        return str(data)\n",
        "\n",
        "\n",
        "with open(file, \"rb\") as logfile:\n",
        "    freader = io.FlowReader(logfile)\n",
        "\n",
        "    with open(output, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        fieldnames = [\n",
        "            \"timestamp\", \"method\", \"url\",\n",
        "            \"full_request\", \"full_response\"\n",
        "        ]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for flow in freader.stream():\n",
        "            req = flow.request\n",
        "            res = flow.response\n",
        "\n",
        "            # full_request = f\"{req.method} {req.path} HTTP/{req.http_version}\\r\\n\"\n",
        "            full_request = \"\".join(f\"{k}: {v}\" for k, v in req.headers.items())\n",
        "            # full_request += \"\\r\\n\"\n",
        "            full_request += clean_bytes(req.content)\n",
        "\n",
        "            full_response = \"\"\n",
        "            if res:\n",
        "                # full_response = f\"HTTP/{res.http_version} {res.status_code} {res.reason}\\r\\n\"\n",
        "                full_response += \"\".join(f\"{k}: {v}\" for k, v in res.headers.items())\n",
        "                # full_response += \"\\r\\n\"\n",
        "                full_response += clean_bytes(res.content)\n",
        "\n",
        "            writer.writerow({\n",
        "                \"timestamp\": datetime.fromtimestamp(req.timestamp_start).isoformat(),\n",
        "                \"method\": req.method,\n",
        "                \"url\": req.pretty_url,\n",
        "                \"full_request\": full_request,\n",
        "                \"full_response\": full_response\n",
        "            })"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(output)\n",
        "# uncomment the \"df\" below to see the preview of the full table\n",
        "\n",
        "# df"
      ],
      "metadata": {
        "id": "GMU-yWLPW1FK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You'll need to put keywords that will be used for filtering here.\n",
        "\n",
        "I put my city / country / postal code / ip address / lat + long. You can also look trhough the parameters and put something specific you want (like screen brightness).\n",
        "\n",
        "Please note that these will be used to find exact matches (too much code and text out there for substring search).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "You can also uncomment the last row in the cell below to find out your ip, coordinates and so on (based on your ip).\n",
        "\n",
        "Please note that if you run it in Google Colab, it will display the data of the Google Server somewhere in the world - in that case, simply open the \"url\" in browser\n"
      ],
      "metadata": {
        "id": "OX5wfeT4Desq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = [\"lat\", \"lon\", \"loc\", \"postal\",\n",
        "            \"Barcelona\"]\n",
        "\n",
        "url = 'https://ipinfo.io/json'\n",
        "# print(requests.get(url).text)"
      ],
      "metadata": {
        "id": "b21Wo2Ry59A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This cell applies the filter to the table from before and adds new columns for matches."
      ],
      "metadata": {
        "id": "xgOEo4lKEhz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = r'\\b(?:' + '|'.join(re.escape(k) for k in keywords) + r')\\b'\n",
        "regex = re.compile(pattern)\n",
        "\n",
        "def extract_context(text, pattern, window=40):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    matches = []\n",
        "    for match in pattern.finditer(text):\n",
        "        start = max(match.start() - window, 0)\n",
        "        end = match.end() + window\n",
        "        context = text[start:end].replace(\"\\n\", \" \").replace(\"\\r\", \"\")\n",
        "        matches.append(f\"...{context}...\")\n",
        "\n",
        "    return \" | \".join(matches)\n",
        "\n",
        "def extract_keywords(text, pattern):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    return \" | \".join(set(match.group() for match in pattern.finditer(text)))\n",
        "\n",
        "df[\"matched_in_request\"] = df[\"full_request\"].apply(lambda x: extract_context(x, regex))\n",
        "df[\"matched_in_response\"] = df[\"full_response\"].apply(lambda x: extract_context(x, regex))\n",
        "df[\"reason_in_request\"] = df[\"full_request\"].apply(lambda x: extract_keywords(x, regex))\n",
        "df[\"reason_in_response\"] = df[\"full_response\"].apply(lambda x: extract_keywords(x, regex))\n",
        "\n",
        "df_filtered = df[(df[\"matched_in_request\"] != \"\") | (df[\"matched_in_response\"] != \"\")]"
      ],
      "metadata": {
        "id": "6X8hrHCsZsik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below if you want to see the preview of the filtered table (all rows have one or more matches with the pattern).\n",
        "\n",
        "Scroll to the right to see the new columns:\n",
        "\n",
        "matched_in_request - +-40 symbols surrounding the match in request\n",
        "\n",
        "matched_in_response\t- +-40 symbols surrounding the match in response\n",
        "\n",
        "reason_in_request\n",
        "\n",
        "reason_in_response\n",
        "\n",
        "In the left part of the table you can also see the index of each row - you might need it later."
      ],
      "metadata": {
        "id": "r7yYDkU9EqC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered"
      ],
      "metadata": {
        "id": "7YV8UzcNYtXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the automation stops and it's time for manual analysis.\n",
        "\n",
        "The data formats are too different to automate this (or too sophisticated for me), + you want to filter out the false positives.\n",
        "\n",
        "Good news: usually this table only has around 10 rows, so it's not hard to look through all of them.\n",
        "\n",
        "The cell simply prints out the entire value of a given row (index, eg 43) and column - use column names from the table above.\n",
        "\n",
        "When the value is too large to read trhough in plain text, I copy it to SublimeText and use the search in there."
      ],
      "metadata": {
        "id": "fHcZjqPa9Zvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[43, \"full_request\"]"
      ],
      "metadata": {
        "id": "UXzWoRQT3RTC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}